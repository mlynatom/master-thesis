{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continued pretraining (CP) using Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install latest version of unsloth\n",
    "#%pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "\n",
    "#%pip install --upgrade unsloth\n",
    "%pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git\n",
    "%pip install --upgrade unsloth_zoo\n",
    "%pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "\n",
    "from unsloth import UnslothTrainingArguments, UnslothTrainer\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "\n",
    "# random state\n",
    "SEED = 42\n",
    "\n",
    "# reproducibility\n",
    "## torch\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "## python\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "## numpy\n",
    "import numpy as np\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.46.3.\n",
      "   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.381 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75e15b85201419eb80f82bffbad37fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45bb0def44d4326ac4bc70ecf1a2f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/230 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ea59f410ab45719a29f15aef16c15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a2f9df1fbd447ea0e175bceb976020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714b4dda856c47c8a33240cb9e89786f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_seq_length = 4096 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = False # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_id,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoftQConfig\n",
    "\n",
    "\"\"\"\n",
    "    This is the sub-configuration class to store the configuration of a [`LoraModel`].\n",
    "\n",
    "    Args:\n",
    "        bits_pattern (`dict`): The mapping from layer names or regexp expression to bits which are different from the\n",
    "            default bits specified by `bits`. For example, `{model.decoder.layers.0.encoder_attn.k_proj: 2`}.\n",
    "        bits (`int`): Quantization bits for LoftQ.\n",
    "        iter (`int`): Alternating iterations for LoftQ.\n",
    "        fake (`bool`): True: use fp16/fp32; used for first time to save weights. False: use bitsandbytes 4bit linear\n",
    "            models. weights can't be saved. Recommend to set to True, save the weights and load the saved weights in 4\n",
    "            bits.\n",
    "    \"\"\"\n",
    "\n",
    "loftq_config = LoftQConfig(loftq_bits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Offloading input_embeddings to disk to save VRAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlynatom/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/unsloth/models/_utils.py:760: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  offloaded_W = torch.load(filename, map_location = \"cpu\", mmap = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Offloading output_embeddings to disk to save VRAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.2.15 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Training embed_tokens in mixed precision to save VRAM\n",
      "Unsloth: Training lm_head in mixed precision to save VRAM\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 256, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "                      \"embed_tokens\", \"lm_head\"], #now also embeddings and lm_head\n",
    "    lora_alpha = 1,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = SEED,\n",
    "    use_rslora = True,  # We support rank stabilized LoRA\n",
    "    init_lora_weights = \"loftq\",\n",
    "    loftq_config = loftq_config, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# # this dataset has already fixed encoding using ftfy (as is used by me in the preprocessing steps of other datasets)\n",
    "# dataset_cs = load_dataset(\"HuggingFaceFW/fineweb-2\", \"ces_Latn\", split=\"train\")\n",
    "# #we need only texts\n",
    "# dataset_cs = dataset_cs.remove_columns([\"id\", \"dump\", \"url\", \"date\", \"file_path\", \"language\", \"language_score\", \"language_script\", \"minhash_cluster_size\", \"top_langs\"])\n",
    "# #shuffle to be sure we select \"random sample\"\n",
    "# dataset_cs = dataset_cs.shuffle(seed=42)\n",
    "# dataset_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_en = load_dataset(\"HuggingFaceFW/fineweb-edu\", \"sample-10BT\", split=\"train\")\n",
    "# dataset_en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_en = dataset_en.remove_columns([\"id\", \"dump\", \"url\", \"file_path\", \"language\", \"language_score\", \"token_count\", \"score\", \"int_score\"])\n",
    "# dataset_en.shuffle(seed=42)\n",
    "# dataset_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import concatenate_datasets\n",
    "# #select 40000 samples (for the initial exp.)\n",
    "\n",
    "# dataset_cs = dataset_cs.select(range(30000))\n",
    "# dataset_en = dataset_en.select(range(10000))\n",
    "\n",
    "# dataset = concatenate_datasets([dataset_cs, dataset_en])\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.save_to_disk(\"data/pretraining/init_31mix_cs-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 40000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "dataset = load_from_disk(\"data/pretraining/init_31mix_cs-en\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f09af05d2040669a1483de3a2e69a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    return {\"text\": [example + tokenizer.eos_token for example in examples[\"text\"]]}\n",
    "\n",
    "dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "V dneÅ¡nÃ­ dobÄ› je wifi pÅ™ipojenÃ­ doma Äi v prÃ¡ci nezbytnostÃ­. AÅ¥ uÅ¾ pracujete z domova, streamujete filmy nebo hrajete online hry, stabilnÃ­ a rychlÃ© pÅ™ipojenÃ­ je klÃ­Äem k ÃºspÄ›chu. Frekvence wifi signÃ¡lu je jednÃ­m z faktorÅ¯, kterÃ½ mÅ¯Å¾e ovlivnit rychlost a stabilitu pÅ™ipojenÃ­. V tomto ÄlÃ¡nku se zamÄ›Å™Ã­me na pÄ›t krokÅ¯, kterÃ© vÃ¡m pomohou optimÃ¡lnÄ› nastavit frekvenci vaÅ¡eho wifi signÃ¡lu.\n",
      "Krok 1: Vyberte sprÃ¡vnÃ½ kanÃ¡l\n",
      "NaÅ¡e wifi sÃ­tÄ› fungujÃ­ na dvou frekvencÃ­ch â€“ 2,4 GHz a 5 GHz. KaÅ¾dÃ¡ z tÄ›chto frekvencÃ­ mÃ¡ urÄitÃ© mnoÅ¾stvÃ­ kanÃ¡lÅ¯. Na frekvenci 2,4 GHz mÃ¡me k dispozici 14 kanÃ¡lÅ¯. KanÃ¡ly jsou vÅ¡ak pÅ™ekrÃ½vajÃ­cÃ­ se, coÅ¾ znamenÃ¡, Å¾e pokud jsou dva sousedÃ­cÃ­ kanÃ¡ly pouÅ¾ity, mohou si vzÃ¡jemnÄ› ruÅ¡it. Proto se v praxi pouÅ¾Ã­vajÃ­ pÅ™evÃ¡Å¾nÄ› kanÃ¡ly 1, 6 a 11.\n",
      "Na frekvenci 5 GHz je k dispozici vÃ­ce kanÃ¡lÅ¯ a ty jsou navÃ­c nezÃ¡vislÃ©, tedy se nepÅ™ekrÃ½vajÃ­. To znamenÃ¡, Å¾e na tÃ©to frekvenci mÅ¯Å¾eme dosÃ¡hnout vyÅ¡Å¡Ã­ pÅ™enosovÃ© rychlosti.\n",
      "Krok 2: ZmÄ›Å™te ruÅ¡enÃ­\n",
      "Pokud chcete zjistit, kterÃ½ kanÃ¡l je pro vÃ¡s nejlepÅ¡Ã­, mÅ¯Å¾ete pouÅ¾Ã­t rÅ¯znÃ© aplikace k mÄ›Å™enÃ­ ruÅ¡enÃ­ wifi. Tyto aplikace skenujÃ­ dostupnÃ© kanÃ¡ly a vyhodnotÃ­, kterÃ½ z nich je nejmÃ©nÄ› ruÅ¡enÃ½. Na zÃ¡kladÄ› tÄ›chto informacÃ­ si pak mÅ¯Å¾ete vybrat optimÃ¡lnÃ­ kanÃ¡l pro svou sÃ­Å¥.\n",
      "Krok 3: Nastavte svÅ¯j router\n",
      "Po zjiÅ¡tÄ›nÃ­ nejvhodnÄ›jÅ¡Ã­ho kanÃ¡lu se pÅ™ihlaste do nastavenÃ­ svÃ©ho routeru. VÄ›tÅ¡ina routerÅ¯ mÃ¡ moÅ¾nost manuÃ¡lnÃ­ho vÃ½bÄ›ru kanÃ¡lu. PÅ™epnÄ›te tedy kanÃ¡l na ten, kterÃ½ jste si vybrali jako optimÃ¡lnÃ­.\n",
      "Krok 4: Zkuste obÄ› frekvence\n",
      "Pokud vÃ¡Å¡ router podporuje obÄ› frekvence, zkuste je obÄ›. Frekvence 5 GHz nabÃ­zÃ­ vyÅ¡Å¡Ã­ pÅ™enosovÃ© rychlosti, ale mÃ¡ menÅ¡Ã­ dosah a hÅ¯Å™e prochÃ¡zÃ­ pÅ™ekÃ¡Å¾kami. Frekvence 2,4 GHz naopak nabÃ­zÃ­ menÅ¡Ã­ rychlost, ale lepÅ¡Ã­ dosah a schopnost prochÃ¡zet pÅ™ekÃ¡Å¾kami. Zkuste tedy obÄ› frekvence a zjistÄ›te, kterÃ¡ z nich funguje pro vaÅ¡i situaci lÃ©pe.\n",
      "Krok 5: Optimizujte umÃ­stÄ›nÃ­ routeru\n",
      "PoslednÃ­m krokem ke zlepÅ¡enÃ­ frekvence wifi je optimÃ¡lnÃ­ umÃ­stÄ›nÃ­ routeru. Router by mÄ›l bÃ½t umÃ­stÄ›n co nejblÃ­Å¾e zaÅ™Ã­zenÃ­m, kterÃ¡ se k wifi pÅ™ipojujÃ­. MÄ›l by bÃ½t takÃ© umÃ­stÄ›n co nejdÃ¡le od pÅ™ekÃ¡Å¾ek, jako jsou stÄ›ny nebo elektronickÃ© zaÅ™Ã­zenÃ­, kterÃ© mohou signÃ¡l ruÅ¡it.\n",
      "ZÃ¡vÄ›r\n",
      "Optimalizace frekvence wifi mÅ¯Å¾e zlepÅ¡it rychlost a stabilitu vaÅ¡eho pÅ™ipojenÃ­. Sledujte tedy naÅ¡e pÄ›t krokÅ¯ a zlepÅ¡ete svÃ© online zÃ¡Å¾itky.\n",
      "HledÃ¡te spolehlivÃ½ internetovÃ½ tarif, kterÃ½ vÃ¡m poskytne superrychlÃ© a stabilnÃ­ pÅ™ipojenÃ­, a to za fÃ©rovou cenu? Pak je tu pro vÃ¡s Tarif pevnÃ½ Eri Internet! ZÃ­skejte vÃ½hody jako roÄnÃ­ platba, zÅ™Ã­zenÃ­ ZDARMA a sleva 600 KÄ kaÅ¾dÃ½ rok! A to nenÃ­ vÅ¡e...\n",
      "NeÄekejte, aÅ¾ vÃ¡m unikne tato skvÄ›lÃ¡ nabÃ­dka! StaÄÃ­ jednoduÅ¡e vyplnit formulÃ¡Å™ na naÅ¡em webu a my se o vÅ¡e postarÃ¡me. NavÃ­c, pokud se pÅ™ihlÃ¡sÃ­te nynÃ­, zÃ­skÃ¡te Eri LiveTV na dva mÄ›sÃ­ce zdarma a mÅ¯Å¾ete sledovat vÅ¡ech 133 TV programÅ¯! UÅ¾ijte si spolehlivÃ½ internet od Eri uÅ¾ dnes!<|end_of_text|>\n",
      "=========================\n",
      "stiskacÃ­ mechanismus dÃ­ky rÃ½chloschnoucÃ­mu inkoustu a tvaru hrotu doporuÄeno i pro levÃ¡ky zabezpeÄuje pÅ™Ã­jemnÃ© a pohodlnÃ© psanÃ­ tlaÄÃ­tko v barvÄ› nÃ¡pnÄ› ruÅ¾ovÃ©, zelenÃ© a svetlomodrÃ© pera dodÃ¡vame s...\n",
      "Ke sprÃ¡vnÃ© registraci chybÃ­ poslednÃ­ krok.\n",
      "Zkontrolujte svÅ¯j e-mail (email@example.com) a kliknutÃ­m na odkaz\n",
      "ve zprÃ¡vÄ› potvrÄte sprÃ¡vnost registrace.\n",
      "DÄ›kujeme, tÃ½m Artikul.<|end_of_text|>\n",
      "=========================\n",
      "LaserovÃ© Å™ezÃ¡nÃ­ trubek\n",
      "- Å˜ezÃ¡nÃ­ a opracovÃ¡nÃ­ nerezovÃ½ch, ocelovÃ½ch uzavÅ™enÃ½ch profilÅ¯ na vysoce vÃ½konnÃ©m CNC laserovÃ©m systÃ©mu s ÄistÃ½m Å™ezem vhodnÃ½m pod povrchovou Ãºpravu\n",
      "- PouÅ¾itÃ­m laseru je optimalizovÃ¡n vÃ½robnÃ­ proces. PÅ™i jedinÃ©m vÃ½robnÃ­m kroku jsou vyÅ™ezÃ¡ny vÅ¡echny otvory, komplexnÃ­ kontury a upravena dÃ©lka trubky. Tak jsou vÃ½raznÄ› sniÅ¾ovÃ¡ny vÃ½robnÃ­ nÃ¡klady uÅ¡etÅ™enÃ­m dalÅ¡Ã­ch operacÃ­ a Äasu (Å™ezÃ¡nÃ­, vrtÃ¡nÃ­, frÃ©zovÃ¡nÃ­ a vysekÃ¡vÃ¡nÃ­).\n",
      "- DÃ¡le jsou stÃ¡le vyvÃ­jeny novÃ© a novÃ© trubkovÃ© konstrukce, kterÃ© vedou k redukci a zjednoduÅ¡enÃ­ nÃ¡slednÃ½ch vÃ½robnÃ­ch operacÃ­. PotÅ™eba i vÃ½roba svaÅ™ovacÃ­ch pÅ™Ã­pravkÅ¯ klesÃ¡ vlivem pouÅ¾Ã­vÃ¡nÃ­ rychlospojek a konektorÅ¯. VodÃ­cÃ­ kolÃ­Äky a zÃ¡mky usnadÅˆujÃ­ nÃ¡slednou montÃ¡Å¾.\n",
      "LaserovÃ½ systÃ©m ADIGE LASERTUBE\n",
      "FlexibilnÃ­ stroj italskÃ© spoleÄnosti BLM Group urÄenÃ½ pro 3D opracovÃ¡nÃ­ uzavÅ™enÃ½ch (trubky a jekle) a otevÅ™enÃ½ch ocelovÃ½ch profilÅ¯ (L, C a U). Je vybavenÃ½ vÃ½kyvnou Å™ezacÃ­ hlavou, kterÃ¡ umoÅ¾Åˆuje Å™ez pod Ãºhlem tam, kde to nÃ¡slednÃ¡ technologie vyÅ¾aduje.\n",
      "- splÅˆuje nejnÃ¡roÄnÄ›jÅ¡Ã­ poÅ¾adavky na laserovÃ© Å™ezÃ¡nÃ­ 3D profilÅ¯ do Ã˜ 220 mm\n",
      "- celkovÃ© rozÅ™ezÃ¡nÃ­ dÃ©lkovÃ©ho profilu na opracovanÃ© jednotlivÃ© kusy vÃ½raznÄ› zkracuje nÃ¡klady a zjednoduÅ¡uje postupy dalÅ¡Ã­ho zpracovÃ¡nÃ­\n",
      "- vysokÃ¡ pÅ™esnost Å™ezanÃ½ch otvorÅ¯ (Â± 0,2 mm)\n",
      "- minimÃ¡lnÃ­ ztrÃ¡ty z tyÄe\n",
      "- gravÃ­rovÃ¡nÃ­\n",
      "- technologickÃ© zÃ¡mky rÅ¯znÃ½ch tvarÅ¯\n",
      "- rohovÃ½ vÃ½Å™ez pro ohnutÃ­ profilu\n",
      "ZpracovatelnÃ© prÅ¯Å™ezy:\n",
      "- KRUHOVÃ s prÅ¯mÄ›rem od 12 mm do 160 mm\n",
      "- ÄŒTVERCOVÃ se stranou od 12 do 120\n",
      "- OBDELNÃKOVÃ a PLOCHOOVÃLNÃ s prÅ¯Å™ezem opsanÃ½m prÅ¯mÄ›rem 170 mm. SÃ­la stÄ›ny Å™ezanÃ©ho materiÃ¡lu: max. 5 mm - Å™ezÃ¡no dusÃ­kem.<|end_of_text|>\n",
      "=========================\n",
      "SportovnÃ­ sluneÄnÃ­ brÃ½le Relax Victoria R5398FKÃ³d: 5015\n",
      "DetailnÃ­ popis produktu\n",
      "Vlastnosti\n",
      "Velikost- Standard\n",
      "Barva- bÃ­lÃ¡\n",
      "MateriÃ¡l- Grilamid TR90\n",
      "PohlavÃ­- pÃ¡nskÃ©\n",
      "PohlavÃ­- dÃ¡mskÃ©\n",
      "MateriÃ¡l ÄoÄky- NÃ¡razuvzdornÃ½ polykarbonÃ¡t\n",
      "Barva ÄoÄky- hnÄ›dÃ¡\n",
      "Kategorie sluneÄnÃ­ho filtru- 2\n",
      "PovrchovÃ¡ Ãºprava ÄoÄky- OCEAN SENSOR\n",
      "CertifikÃ¡t\n",
      "Garantujeme provÄ›Å™enou bezpeÄnost.\n",
      "TR90\n",
      "ExtrÃ©mnÄ› lehkÃ½ a pÅ™itom velmi odolnÃ½ high-tec materiÃ¡l s nadprÅ¯mÄ›rnou pruÅ¾nostÃ­ a tvarovou pamÄ›tÃ­, zvÃ½Å¡enÃ½ komfort noÅ¡enÃ­.\n",
      "ProtiskluzovÃ© plochy\n",
      "ProtiskluzovÃ© nosnÃ­ky a straniÄky. ZamezujÃ­ skluzu brÃ½lÃ­, kterÃ© perfektnÄ› drÅ¾Ã­ na obliÄeji.\n",
      "UpravitelnÃ½ nosnÃ­k\n",
      "VÄ›tÅ¡Ã­ pohodlÃ­ pÅ™i noÅ¡enÃ­, nosnÃ­k lze pÅ™izpÅ¯sobit tvaru nosu.\n",
      "PolykarbonÃ¡t\n",
      "TÃ©mÄ›Å™ nerozbitnÃ½ materiÃ¡l ÄoÄek zajiÅ¡Å¥uje vyÅ¡Å¡Ã­ bezpeÄnost oÄÃ­.\n",
      "MÄ›kkÃ© pouzdro\n",
      "V mÄ›kkÃ©m mikrovlÃ¡knovÃ©m pouzdru se brÃ½le nepoÅ¡krÃ¡bou a navÃ­c jÃ­m lze brÃ½le dobÅ™e vyÄistit.\n",
      "DoplÅˆkovÃ© parametry\n",
      "|Kategorie:||BrÃ½le|\n",
      "|ZÃ¡ruka:||24|<|end_of_text|>\n",
      "=========================\n",
      "- 812 008\n",
      "Å˜Ã­kÃ¡ se tomu domÃ½Å¡lenÃ­. A je nebezpeÄnÃ©. Nebo snad pomÃ¡hÃ¡ pÅ™edchÃ¡zet problÃ©mÅ¯m? DokonalÃ¡ myÅ¡lenka v tomto komiksu vystihuje to, jak smÃ½Å¡lÃ­me o ostatnÃ­ch v porovnÃ¡nÃ­ se skuteÄnostÃ­. Co si o vÃ¡s a situaci kolem vÃ¡s Å™Ã­kajÃ­ lidÃ© skuteÄnÄ› versus co si myslÃ­te, Å¾e si o nÃ­ domnÄ›le Å™Ã­kajÃ­? No, abychom se v tom neztratili, bude lepÅ¡Ã­ si to zÃ¡bavnÃ½m zpÅ¯sobem ukÃ¡zat v tomto dokonalÃ©m komiksu.\n",
      "- 304 131\n",
      "Å½enskÃ¡ logika prostÄ› nenÃ­ logickÃ¡. Jak jinak byste vysvÄ›tlili, Å¾e pokud vÃ¡s podvede holka, nakonec to vÅ¡echno dopadne tak, Å¾e byste se mÄ›li omlouvat vy? No, nechtÄ›li bychom teÄ bÃ½t v kÅ¯Å¾i chudÃ¡ka Derpa (nebo toho chlÃ¡pka, co po dobu trvÃ¡nÃ­ komiksu drÅ¾Ã­ ukÃ¡zkovÃ½ poker face). PonauÄenÃ­ pro dneÅ¡nÃ­ den je velmi jednoduchÃ© - kdyÅ¾ uÅ¾ mÃ¡te potÅ™ebu svou pÅ™Ã­telkyni sledovat, nikdy jÃ­ to nepÅ™iznÃ¡vejte.\n",
      "- 301 603\n",
      "Tento jednoduchÃ½ test osobnosti je zaloÅ¾en na tom, Å¾e se ÄlovÄ›k podÃ­vÃ¡ na obrÃ¡zku a Å™ekne, kterÃ¡ vÄ›c ho na nÄ›m zaujala jako prvnÃ­. V tomto pÅ™Ã­padÄ› existujÃ­ 3 moÅ¾nosti, kterÃ© vÃ¡m nÃ¡slednÄ› poodhalÃ­ skrytou tvÃ¡Å™ vaÅ¡Ã­ osobnosti. Test si mÅ¯Å¾ete vyzkouÅ¡et takÃ© s pÅ™Ã­teli, protoÅ¾e to, co hned vidÃ­ jeden ÄlovÄ›k, mÅ¯Å¾e bÃ½t druhÃ©mu (minimÃ¡lnÄ› v prvnÃ­ moment) ÃºplnÄ› skryto.\n",
      "- 307 788\n",
      "KaÅ¾dÃ¡ hra mÃ¡ jinÃ¡ specifika. PojÄme se podÃ­vat na jednotlivÃ© stÅ™Ã­leÄky, ve kterÃ½ch mÃ¡me pÅ™idÄ›lenou nÄ›jakou hernÃ­ mechaniku. Jak si modelovÃ½ hrÃ¡Ä poradÃ­ s protivnÃ­ky nebo jakou finty je moÅ¾nÃ© pouÅ¾Ã­t? NÄ›kdy se bohuÅ¾el i nejzkuÅ¡enÄ›jÅ¡Ã­m hrÃ¡ÄÅ¯m stÃ¡vÃ¡, Å¾e je jim k niÄemu. NÃ¡sledujÃ­cÃ­ obrÃ¡zky pochopÃ­ jen opravdovÃ½ pÅ™Ã­znivce her. RozkliknÄ›te si tedy hrÃ¡ÄskÃ½ komiks a pÅ™ipomeÅˆte si Äasy, kdyÅ¾ jste proÅ¾Ã­vali to napÄ›tÃ­.\n",
      "- 456 923\n",
      "V nynÄ›jÅ¡Ã­m modernÃ­m svÄ›tÄ› je sport stejnÄ› tak populÃ¡rnÃ­, jako tomu bylo v dÃ¡vnÃ½ch dobÃ¡ch. KaÅ¾dÃ½ druhÃ½ ÄlovÄ›k chodÃ­ potit krev do posilovny, nebo cviÄÃ­ jÃ³gu, bÄ›hÃ¡ po ulicÃ­ch v dopolednÃ­ch hodinÃ¡ch nebo dodrÅ¾uje pÅ™Ã­snÃ½ jÃ­delnÃ­Äek plnÃ½ zdravÃ½ch pochutin. Je to tak, McDonaldu a ostatnÃ­m fast foodÅ¯m uÅ¾ odzvonilo a v mÃ³dÄ› jsou smoothie plnÃ© vitamÃ­nÅ¯ pro skvÄ›lou rovnovÃ¡hu a nastartovÃ¡nÃ­ dne. Co se tÃ½Äe cviÄenÃ­, jsou zde urÄitÃ¡ fakta, Å™eknÄ›me mÃ½ty, kterÃ½m hodnÄ› lidÃ­ neustÃ¡le vÄ›Å™Ã­ a kterÃ¡ jsou naprosto Å¡patnÄ›! JakÃ©? PodÃ­vejte se sami!\n",
      "- 409 916\n",
      "KaÅ¾dÃ¡ Å¾ena je jedineÄnÃ¡, to takÃ© v tom, co dÄ›lÃ¡. PodÃ­vejte se na komiks Å¾enskÃ© pÅ™Ã­bÄ›hy z brightside.me, kterÃ© vytvoÅ™ila autorka Valeriya Fortuna a zaruÄenÄ› se mohly kaÅ¾dÃ© z nich stÃ¡t. NejrÅ¯znÄ›jÅ¡Ã­ kaÅ¾dodennÃ­ situace, obÄasnÃ© nezdary, chyby nebo zlomyslnosti Å¾en. PÅ™iznejme si, Å¾e kaÅ¾dÃ¡ mÃ¡ i svÃ© osobitÃ© manÃ½ry a nÄ›kterÃ© pochopÃ­ jen mÃ¡lokterÃ½ muÅ¾, ale pÅ™es to bez nÄ›Å¾nÃ©ho pohlavÃ­ by byl svÄ›t chmurnÄ›jÅ¡Ã­ a smutnÄ›jÅ¡Ã­. PouÅ¡tÃ­me tedy do svÄ›ta dalÅ¡Ã­ galerii o Å¾enÃ¡ch a jejich Å¾ivotÄ› z rubriky SrandovnÃ­ obrÃ¡zky.\n",
      "- 612 811\n",
      "VÃ­te, proÄ dinosauÅ™i vyhinuli? A takÃ© to, jak vznikli? DokonalÃ½ komiks od ItsTheTie vyobrazuje Boha, strejdu Satana a moment, kterÃ½ tam nahoÅ™e speÄetil osud jeÅ¡tÄ›rek pÅ™ed 65 miliony let (i kdyÅ¾ ony to nebyly ani tak jeÅ¡tÄ›rky jako slepice, podle nejnovÄ›jÅ¡Ã­ch vÄ›deckÃ½ch dÅ¯kazÅ¯, ale vem to Äert, Å¾e?). Jsou to hadi a jdou do pekel! :-D\n",
      "- 304 950\n",
      "Velmi nÃ¡s zajÃ­mÃ¡, kolik z vÃ¡s vyhedÃ¡ po pÅ™eÄtenÃ­ tÃ©to galerie odbornonu pomoc u psychologa, takÅ¾e nÃ¡m nezapomeÅˆte sdÄ›lit svÅ¯j verdikt v komentÃ¡Å™i! MÃ¡me pro vÃ¡s dalÅ¡Ã­ psychologickÃ½ test, kterÃ½ odhalÃ­ vaÅ¡e mentÃ¡lnÃ­ poruchy, o kterÃ½ch jste ani nevÄ›dÄ›li! StaÄÃ­ si udÄ›lat tento jednoduchÃ½ test. PozornÄ› se podÃ­vejte na kaÅ¾dÃ© z nÃ¡sledujÃ­cÃ­ch Å¡esti koleÄek. Nenechte se zmÃ¡st, nenÃ­ to test u oÄnÃ­ho lÃ©kaÅ™e, ale probÃ­hÃ¡ tÃ©mÄ›Å™ stejnÄ›. VidÃ­te v kaÅ¾dÃ©m koleÄku ÄÃ­slo? Pak je vÅ¡e v poÅ™Ã¡dku. Pokud ale nÄ›jakÃ© ÄÃ­slo nedokÃ¡Å¾ete identifikovat, pÅ™eÄtÄ›te si svoji charakteristiku!\n",
      "- 323 344\n",
      "MazlenÃ­ mÃ¡ rÃ¡d kaÅ¾dÃ½. NÄ›kdo s opaÄnÃ½m pohlavÃ­m, nÄ›kdo se stejnÃ½m pohlavÃ­m, jinÃ½ zase se svÃ½mi domÃ¡cÃ­mi mazlÃ­Äky, Äi nedÃ¡vnou zakoupenÃ½m kalashnikovem - to se tÃ½kÃ¡ vÃ­ce fanouÅ¡kÅ¯ armÃ¡dnÃ­ch zÃ¡leÅ¾itostÃ­. ProÄ je ale mazlenÃ­ s partnerem tak dÅ¯leÅ¾itÃ©? A proÄ je vlastnÄ› nejlepÅ¡Ã­? V tomto ponÄ›kud krÃ¡tkÃ©m, zato vÃ½stiÅ¾nÃ©m komiksu pochopÃ­te.\n",
      "- 292 835\n",
      "Bezesporu k nejoblÃ­benÄ›jÅ¡Ã­m se na internetu Å™adÃ­ komiksy s Hipsterkou a HrÃ¡Äkou od Jago Dibuja. V tÃ©to kolekci komiksÅ¯ od tohoto autora si ukÃ¡Å¾eme nÄ›kolik dechberoucÃ­ch momentÅ¯ s dÄ›tmi a postaviÄkami z komiksu, kterÃ© zcela oÄividnÄ› devalvujÃ­ veÅ¡kerÃ© zÃ¡sady a pravidla, jimiÅ¾ se dospÄ›lÃ­ Å™Ã­dÃ­ vÅ¯Äi dÄ›tem. ZkrÃ¡tka, hipsterka a hrÃ¡Äka si neberou servÃ­tky a s dÄ›tmi to opravdu \"umÃ­\". :-D\n",
      "- 404 794\n",
      "Tohle je Harry Potter. A postavy, kterÃ© nakreslil jeden *bezejmennÃ½* umÄ›lec dle popisu v knize a souÄasnÄ› je postavil vstÅ™Ã­c kontrastu podoby, kterou tyto postavy zÃ­skaly ve filmu. Jak moc se liÅ¡Ã­ samotnÃ½ Harry? A jak moc Hermiona? SleÄna GrangerovÃ¡ byla pÅ¯vodnÄ› pizizubkou, v originÃ¡lnÃ­m filmu vÅ¡ak ztratila tento defekt a stala se ponÄ›kud atraktivnÃ­ bordelmÃ¡mou. Å koda, Å¾e se autoÅ™i neÅ™Ã­dili popisem postav u dalÅ¡Ã­ch charakterÅ¯. A nebo se trefili? Co myslÃ­te?\n",
      "- 374 057\n",
      "PonÄ›kud cynickÃ© a plnÃ© sarkasmu jsou nÃ¡sledujÃ­cÃ­ omalovÃ¡nky, striktnÄ› urÄenÃ© jen dospÄ›lÃ½m lidem. To, kdybyste se fakt hodnÄ› nudili ve svÃ©m zamÄ›stnÃ¡nÃ­, mÅ¯Å¾ete pak zkusit nalistovat na strÃ¡nku s titulkem \"Pokuste se utÃ©ct z Friendzone\". V tÄ›chto omalovÃ¡nkÃ¡ch totiÅ¾ budete nejen omalovÃ¡vat, nÃ½brÅ¾ takÃ© utÃ­kat. A nejen to. PodÃ­vejte se sami. A kreslete!\n",
      "- 393 788\n",
      "V tÃ©to galerii se mÅ¯Å¾ete pÅ™esvÄ›dÄit, Å¾e vÄ›tÅ¡ina postav z Harryho Pottera opravdu vyrostla do krÃ¡sy. PÅ™Ã­kladem mÅ¯Å¾e bÃ½t tÅ™eba Matthew Lewis, kterÃ½ si zahrÃ¡l postavu Neville Longbottoma. Odtud takÃ© novÃ© pÅ™Ã­davnÃ© jmÃ©no longbottoming, kterÃ© bychom mohli pÅ™eloÅ¾it jako dokrÃ¡syrostoucÃ­.\n",
      "- 555 182\n",
      "Mezi nÃ¡mi Å¾enami-obÄas mÃ¡me sloÅ¾itÃ½ Å¾ivot, za kterÃ½ si obÄas mÅ¯Å¾eme i samy. A sloÅ¾itÃ½ Å¾ivotsi nÄ›kdy Å¾Ã¡dÃ¡ i sloÅ¾itÃ© Å™eÅ¡enÃ­ na sloÅ¾itÃ© situace. NenÃ­ divu, Å¾e nÃ¡m muÅ¾i dost Äasto nerozumÃ­. Ano, hÃ¡dÃ¡te sprÃ¡vnÄ›, dnes pro vÃ¡s mÃ¡me vtipnÄ› udÄ›lanou galerii o Å¾enÃ¡ch takovÃ½ch, jakÃ© doopravdy jsou. KlidnÄ› se s vÃ¡mi vsadÃ­m, Å¾e alespoÅˆ jednou v Å¾ivotÄ› se kaÅ¾dÃ¡ Å¾ena ocitla v jednÃ© z tÄ›ch patnÃ¡cti situacÃ­. JÃ¡ tÅ™eba snad skoro ve vÅ¡ech. ZajÃ­mÃ¡ vÃ¡s logika Å¾en? Pak tahle galerie ÄekÃ¡ prÃ¡vÄ› na vÃ¡s!\n",
      "- 442 641\n",
      "KdyÅ¾ jste byli malÃ­, urÄitÄ› vÃ¡m rodiÄe Å™Ã­kali, abyste si neÄetli po tmÄ›, Å¾e si zkazÃ­te oÄi. MoÅ¾nÃ¡, Å¾e nÄ›kterÃ© z vÃ¡s napadlo, Å¾e kdyÅ¾ potom snÃ­te mrkev, kterÃ¡ je podle vaÅ¡ich rodiÄÅ¯ zdravÃ¡ na oÄi, tak si ten zrak zlepÅ¡Ã­te a oba dva jevy se vynulujÃ­. TeÄ vÃ¡s ale musÃ­me zklamat - nejenÅ¾e to takhle na svÄ›tÄ› nefunguje, ale oba dva fakty jsou ve skuteÄnosti mÃ½ty. A patÅ™Ã­ do Å¡irokÃ© skupiny mÃ½tÅ¯, kterÃ© nÃ¡m odmala vtloukali do hlavy. TakÅ¾e o Äem vÅ¡em Å¾e nÃ¡m to rodiÄe, pÅ™Ã­buznÃ­, ba dokonce i uÄitelÃ© ve Å¡kole lhali?\n",
      "- 288 805\n",
      "Lehce starÅ¡Ã­ generaci, ale ne zase ÃºplnÄ› starou, dost moÅ¾nÃ¡ udeÅ™Ã­ do oÄÃ­ fakt, Å¾e herec Samy Naceri, hlavnÃ­ postava filmovÃ© sÃ©rie Taxi, mÃ¡ ve skuteÄnosti uÅ¾ 53 let. Bum. A to si ho celÃ¡ Å™ada z nÃ¡s pamatuje jako mlÃ¡dence, co se prohÃ¡nÃ­ italskÃ½mi ulicemi mÄ›st ve svÃ½m super ultra dokonalÃ©m fÃ¡ru s cedulkou \"odvezu vÃ¡s kamkoliv a za pÅ™Ã­platek mi mÅ¯Å¾ete v autÄ› zvracet\". KterÃ© celebrity jsou vÅ¡ak stejnÄ› starÃ© a neÅ™ekli byste to do nich? V tÃ©to galerii zahlÃ©dnete filmovÃ© here jako Silvester Stalone nebo dÄ›deÄka Chucka Norrise. Vedle nich i Terryho Crewse a nebo kapitÃ¡na Picarda z legendÃ¡rnÃ­ho Star Treku.\n",
      "- 1 838 735\n",
      "A kdyÅ¾ Å™Ã­kÃ¡me \"aÅ¾ do konce\", tak myslÃ­me zcela vÃ¡Å¾nÄ›, abyste tento rage komiks pÅ™eÄetli celÃ½. PatÅ™Ã­ do zlatÃ© sbÃ­rky nejlepÅ¡Ã­ch rage komiksÅ¯, kterÃ© najdete na Trololol. A i pokud jste se s nÃ­m uÅ¾ nÄ›kdy setkali, urÄitÄ› vÃ¡s repete neurazÃ­. ProtoÅ¾e tohle patÅ™Ã­ k nestÃ¡rnoucÃ­m vtipÅ¯m! :-D\n",
      "- 681 351\n",
      "Pokud mÃ¡te velkÃ¡ prsa, nese to s sebou pochopitelnÄ› celou Å™adu vÃ½hod, zejmÃ©na co se tÃ½Äe muÅ¾Å¯. NicmÃ©nÄ› kaÅ¾dÃ¡ bohatÄ› obdaÅ™enÃ¡ Å¾ena vÃ¡m potvrdÃ­, Å¾e to mÃ¡ takÃ© velkou spoustu nevÃ½hod, kterÃ½ vÃ¡m dokÃ¡Å¾ou pÄ›knÄ› znepÅ™Ã­jemnit Å¾ivot.\n",
      "- 286 354\n",
      "Vztah dvou lidÃ­ je zaloÅ¾en na vÃ­ce vÄ›cech, neÅ¾ je lÃ¡ska, tolerance a porozumÄ›nÃ­. Nemalou roli hraje i sexuÃ¡lnÃ­ Å¾ivot. Asi vÅ¡ichni se shodneme na tom, Å¾e to, co se odehrÃ¡vÃ¡ ve filmech pro dospÄ›lÃ©, nemÃ¡ vÅ¯bec nic spoleÄnÃ©ho s lÃ¡skou. DokÃ¡Å¾ete si pÅ™edstavit, Å¾e byste to dÄ›lali tak, jak se to dÄ›lÃ¡ ve filmech pro dospÄ›lÃ©? V tÃ©to galerii vÃ¡m ukÃ¡Å¾eme, jak by to vypadalo! PodÃ­vejte se sami.\n",
      "- 292 831\n",
      "O pÅ™estÃ¡vce se ve Å¡kole dÃ¡ dÄ›lat spousta vÄ›cÃ­. NÄ›kdo ji vyuÅ¾ije k tomu, aby si dodÄ›lal Ãºkol ze vÄerejÅ¡ka, jinÃ½ se zase snaÅ¾Ã­ nauÄit se na test, dalÅ¡Ã­ hraje hry na mobilu, kdeÅ¾to nÄ›kdo dalÅ¡Ã­ si jde popovÃ­dat s kamarÃ¡dy. Ale o pÅ™estÃ¡vkÃ¡ch se dajÃ­ dÄ›lat i jinÃ© vÄ›ci, aÄkoli by se dÄ›lat nemÄ›ly. NepÅ™emÃ½Å¡leli jste nÄ›kdy o tom, Å¾e byste si se svou poloviÄkou nÄ›kam zalezli a trochu se tam uvolnili?\n",
      "- 417 710\n",
      "Autor mnoha komiksÅ¯ a rÅ¯znÃ½ch kreslenÃ½ch postav Yehuda Adi Devir ukÃ¡zal svÄ›tu svoji sÃ©rii obrÃ¡zkÅ¯, ve kterÃ© je vykreslenÃ½ Å¾ivot s jeho manÅ¾elkou Mayou. Ilutrace jsou velmi vtipnÃ©, milÃ© a zahÅ™ejÃ­ u srdce. AÅ¥ uÅ¾ jste ve vÃ¡Å¾nÃ©m vztahu Äi manÅ¾elstvÃ­, najdete alespoÅˆ jeden obrÃ¡zek, kterÃ½ se k vÃ¡m hodÃ­.\n",
      "- 441 042\n",
      "Autorka, kterÃ¡ se vydÃ¡vÃ¡ pod nickem C-Cassandra, zobrazila muÅ¾Å¯m 7 vÄ›cÃ­, se kterÃ½mi se Å¾eny trÃ¡pÃ­ a kterÃ© muÅ¾i nikdy neocenÃ­. MuÅ¾i vÅ¡ak zcela jistÄ› ocenÃ­ dvÄ› vÄ›ci, kterÃ© Å¾eny zase tak moc netrÃ¡pÃ­. PrvnÃ­ je nahota. A druhÃ¡ je pivo v ruce. TakÅ¾e pokud na to chcete jÃ­t jednoduÅ¡e, prostÄ› tÄ›chto jinak dÅ¯leÅ¾itÃ½ch sedm bodÅ¯ vynechte.<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "for row in dataset[:5][\"text\"]:\n",
    "    print(\"=========================\")\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnslothKLLossTrainer(UnslothTrainer):\n",
    "    def __init__(self, ref_model, kl_weight=0.1, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.ref_model = ref_model\n",
    "        self.ref_model.eval()\n",
    "        self.kl_weight = kl_weight\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        #account for the actual number of items in the batch\n",
    "        if num_items_in_batch is not None:\n",
    "            effective_batch_size = num_items_in_batch\n",
    "        else:\n",
    "            effective_batch_size = labels.size(0)\n",
    "        \n",
    "        #cross entropy loss\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "        loss_ce = loss_fct(logits.view(-1, logits.shape[-1]), labels.view(-1))\n",
    "        loss_ce = loss_ce / effective_batch_size # Scale by actual number of items\n",
    "\n",
    "        # KL loss\n",
    "        with torch.no_grad():\n",
    "            ref_outputs = self.ref_model(**inputs)\n",
    "            ref_logits = ref_outputs.logits\n",
    "        \n",
    "        loss_kl_fct = torch.nn.KLDivLoss(reduction=\"sum\")\n",
    "        loss_kl = loss_kl_fct(\n",
    "            torch.nn.functional.log_softmax(logits, dim=-1),\n",
    "            torch.nn.functional.softmax(ref_logits, dim=-1),\n",
    "        )\n",
    "        loss_kl = loss_kl / effective_batch_size # Scale by actual number of items\n",
    "\n",
    "        total_loss = loss_ce + self.kl_weight*loss_kl\n",
    "\n",
    "        return (total_loss, outputs) if return_outputs else total_loss\n",
    "\n",
    "from transformers.utils.import_utils import is_torch_xla_available\n",
    "#from transformers.trainer_utils import SaveStrategy\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "\n",
    "class PerplexityTrainer(UnslothTrainer):\n",
    "    # def training_step(self, model, inputs, num_items_in_batch):\n",
    "    #     loss = super().training_step(model, inputs, num_items_in_batch)\n",
    "\n",
    "    #     # log perplexity\n",
    "    #     perplexity = torch.exp(loss)\n",
    "    #     self.log({\"train_perplexity\": perplexity})\n",
    "\n",
    "    #     return loss\n",
    "    def _maybe_log_save_evaluate(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval):\n",
    "        if self.control.should_log and self.state.global_step > self._globalstep_last_logged:\n",
    "            if is_torch_xla_available():\n",
    "                xm.mark_step()\n",
    "\n",
    "            logs: Dict[str, float] = {}\n",
    "\n",
    "            # all_gather + mean() to get average loss over all processes\n",
    "            tr_loss_scalar = self._nested_gather(tr_loss).mean().item()\n",
    "\n",
    "            # reset tr_loss to zero\n",
    "            tr_loss -= tr_loss\n",
    "\n",
    "            loss = round(tr_loss_scalar / (self.state.global_step - self._globalstep_last_logged), 4)\n",
    "            logs[\"loss\"] = loss\n",
    "\n",
    "            #PERPLEXITY\n",
    "            logs[\"perplexity\"] = round(float(np.exp(tr_loss_scalar)), 4)\n",
    "            #########################\n",
    "\n",
    "\n",
    "            if grad_norm is not None:\n",
    "                logs[\"grad_norm\"] = grad_norm.detach().item() if isinstance(grad_norm, torch.Tensor) else grad_norm\n",
    "            logs[\"learning_rate\"] = self._get_learning_rate()\n",
    "\n",
    "            self._total_loss_scalar += tr_loss_scalar\n",
    "            self._globalstep_last_logged = self.state.global_step\n",
    "            self.store_flos()\n",
    "\n",
    "            self.log(logs)\n",
    "\n",
    "        metrics = None\n",
    "        if self.control.should_evaluate:\n",
    "            metrics = self._evaluate(trial, ignore_keys_for_eval)\n",
    "\n",
    "        if self.control.should_save:\n",
    "            self._save_checkpoint(model, metrics=metrics)\n",
    "            self.control = self.callback_handler.on_save(self.args, self.state, self.control)\n",
    "\n",
    "TrainerClass = PerplexityTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EvalPrediction\n",
    "import numpy as np\n",
    "\n",
    "#prepare perplexity computation\n",
    "def compute_metrics(pred: EvalPrediction):\n",
    "    losses = pred.losses\n",
    "\n",
    "    mean_loss = np.mean(losses)\n",
    "\n",
    "    try:\n",
    "        perplexity = np.exp(mean_loss)\n",
    "    except OverflowError:\n",
    "        perplexity = float(\"inf\")\n",
    "\n",
    "    return {\"perplexity\": perplexity}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlynatom/master-thesis-repository-tomas-mlynar/unsloth_compiled_cache/UnslothSFTTrainer.py:578: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/mlynatom/master-thesis-repository-tomas-mlynar/unsloth_compiled_cache/UnslothSFTTrainer.py:592: UserWarning: You passed a `dataset_num_proc` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/mlynatom/master-thesis-repository-tomas-mlynar/unsloth_compiled_cache/UnslothSFTTrainer.py:606: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898ffbd7b42b435d9c429d38fb3dc77d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/40000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "trainer = UnslothTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset.shuffle(seed=SEED),\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    # ref_model=copy.deepcopy(model),\n",
    "    #compute_metrics=compute_metrics,\n",
    "    \n",
    "    args = UnslothTrainingArguments(\n",
    "        per_device_train_batch_size = 64,\n",
    "        gradient_accumulation_steps = 16,\n",
    "        warmup_ratio = 0.05,\n",
    "        num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        #max_steps = 1000,\n",
    "        learning_rate = 2e-4,\n",
    "        embedding_learning_rate = 4e-5,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = SEED,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"wandb\", # Use this for WandB etc\n",
    "        run_name=\"llama3.2-1b-cp-exp-loftq\",\n",
    "        # eval_strategy = \"steps\",\n",
    "        # eval_steps = 50,\n",
    "        \n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA A100-SXM4-40GB. Max memory = 39.381 GB.\n",
      "3.514 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "#Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 40,000 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 64 | Gradient Accumulation steps = 16\n",
      "\\        /    Total batch size = 1,024 | Total steps = 39\n",
      " \"-____-\"     Number of trainable parameters = 705,691,648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Setting lr = 4.00e-05 instead of 2.00e-04 for embed_tokens.\n",
      "Unsloth: Setting lr = 4.00e-05 instead of 2.00e-04 for lm_head.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmlynatom\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mlynatom/master-thesis-repository-tomas-mlynar/wandb/run-20250226_093358-ioydrdok</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mlynatom/huggingface/runs/ioydrdok' target=\"_blank\">llama3.2-1b-cp-exp-loftq</a></strong> to <a href='https://wandb.ai/mlynatom/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mlynatom/huggingface' target=\"_blank\">https://wandb.ai/mlynatom/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mlynatom/huggingface/runs/ioydrdok' target=\"_blank\">https://wandb.ai/mlynatom/huggingface/runs/ioydrdok</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6/39 14:53 < 2:02:54, 0.00 it/s, Epoch 0.13/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.909600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.845400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.885000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlynatom/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/unsloth/models/_utils.py:592: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  source = re.sub(\"([^\\.])nn\\.\", r\"\\1torch.nn.\", source)\n",
      "/home/mlynatom/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/unsloth/models/_utils.py:855: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  \"self.rotary_emb = .+?\\)\", function,\n",
      "/home/mlynatom/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/unsloth/models/_utils.py:955: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  \"self.rotary_emb = .+?\\)\", function,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:380\u001b[0m, in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
      "File \u001b[0;32m<string>:31\u001b[0m, in \u001b[0;36m_unsloth_training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/unsloth/models/_utils.py:1077\u001b[0m, in \u001b[0;36m_unsloth_pre_compute_loss\u001b[0;34m(self, model, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1071\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[1;32m   1072\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsloth: Not an error, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept `num_items_in_batch`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing gradient accumulation will be very slightly less accurate.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m   1074\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1075\u001b[0m     )\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m-> 1077\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_compute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/transformers/trainer.py:3633\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3631\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3632\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3633\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3634\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3635\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/accelerate/utils/operations.py:820\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/accelerate/utils/operations.py:808\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/torch/_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m prior \u001b[38;5;241m=\u001b[39m _maybe_set_eval_frame(callback)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    634\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/unsloth/models/llama.py:1216\u001b[0m, in \u001b[0;36mPeftModelForCausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, num_logits_to_keep, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_dynamo\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mPeftModelForCausalLM_fast_forward\u001b[39m(\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1215\u001b[0m ):\n\u001b[0;32m-> 1216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:197\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/unsloth/models/llama.py:1109\u001b[0m, in \u001b[0;36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m RETURN_LOGITS \u001b[38;5;129;01mand\u001b[39;00m HAS_CUT_CROSS_ENTROPY \u001b[38;5;129;01mand\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1108\u001b[0m     n_items \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_items\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1109\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mfused_linear_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlm_weight\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlm_head\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogit_softcapping\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogit_softcapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1117\u001b[0m         output \u001b[38;5;241m=\u001b[39m (logits,) \u001b[38;5;241m+\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/unsloth_zoo/loss_utils.py:154\u001b[0m, in \u001b[0;36mfused_linear_cross_entropy\u001b[0;34m(hidden_states, lm_weight, labels, num_items_in_batch, ignore_index, reduction, logit_softcapping, accuracy_threshold)\u001b[0m\n\u001b[1;32m    152\u001b[0m reduction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logit_softcapping \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: logit_softcapping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlm_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43msoftcap\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogit_softcapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshift\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_eps\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maccuracy_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m num_items_in_batch\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/cut_cross_entropy/linear_cross_entropy.py:58\u001b[0m, in \u001b[0;36mlinear_cross_entropy\u001b[0;34m(e, c, targets, ignore_index, softcap, reduction, shift, filter_eps, impl)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     54\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCCE does not support MacOS. Please use torch_compile when running on MacOS instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m         )\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m cce_linear_cross_entropy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcce_linear_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoftcap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_eps\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_compile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_compile_linear_cross_entropy(\n\u001b[1;32m     63\u001b[0m         e, c, targets, ignore_index, softcap, reduction, shift\n\u001b[1;32m     64\u001b[0m     )\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/cut_cross_entropy/cce.py:163\u001b[0m, in \u001b[0;36mcce_linear_cross_entropy\u001b[0;34m(e, c, targets, ignore_index, softcap, reduction, shift, filter_eps)\u001b[0m\n\u001b[1;32m    160\u001b[0m e \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    161\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m--> 163\u001b[0m valids \u001b[38;5;241m=\u001b[39m \u001b[43m_build_flat_valids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m e \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    166\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/cut_cross_entropy/utils.py:38\u001b[0m, in \u001b[0;36m_build_flat_valids\u001b[0;34m(targets, ignore_index, shift)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m---> 38\u001b[0m valids \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m shift:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m valids\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4329.0353 seconds used for training.\n",
      "72.15 minutes used for training.\n",
      "Peak reserved memory = 19.932 GB.\n",
      "Peak reserved memory for training = 17.297 GB.\n",
      "Peak reserved memory % of max memory = 50.613 %.\n",
      "Peak reserved memory for training % of max memory = 43.922 %.\n"
     ]
    }
   ],
   "source": [
    "#Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
