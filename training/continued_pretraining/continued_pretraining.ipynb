{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continued pretraining (CP) using Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install latest version of unsloth\n",
    "#%pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "\n",
    "#%pip install --upgrade unsloth\n",
    "%pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git\n",
    "%pip install --upgrade unsloth_zoo\n",
    "%pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "\n",
    "from unsloth import UnslothTrainingArguments, UnslothTrainer\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "\n",
    "# random state\n",
    "SEED = 42\n",
    "\n",
    "# reproducibility\n",
    "## torch\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "## python\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "## numpy\n",
    "import numpy as np\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.46.3.\n",
      "   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.381 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75e15b85201419eb80f82bffbad37fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45bb0def44d4326ac4bc70ecf1a2f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/230 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ea59f410ab45719a29f15aef16c15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a2f9df1fbd447ea0e175bceb976020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714b4dda856c47c8a33240cb9e89786f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_seq_length = 4096 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = False # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_id,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoftQConfig\n",
    "\n",
    "\"\"\"\n",
    "    This is the sub-configuration class to store the configuration of a [`LoraModel`].\n",
    "\n",
    "    Args:\n",
    "        bits_pattern (`dict`): The mapping from layer names or regexp expression to bits which are different from the\n",
    "            default bits specified by `bits`. For example, `{model.decoder.layers.0.encoder_attn.k_proj: 2`}.\n",
    "        bits (`int`): Quantization bits for LoftQ.\n",
    "        iter (`int`): Alternating iterations for LoftQ.\n",
    "        fake (`bool`): True: use fp16/fp32; used for first time to save weights. False: use bitsandbytes 4bit linear\n",
    "            models. weights can't be saved. Recommend to set to True, save the weights and load the saved weights in 4\n",
    "            bits.\n",
    "    \"\"\"\n",
    "\n",
    "loftq_config = LoftQConfig(loftq_bits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Offloading input_embeddings to disk to save VRAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlynatom/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/unsloth/models/_utils.py:760: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  offloaded_W = torch.load(filename, map_location = \"cpu\", mmap = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Offloading output_embeddings to disk to save VRAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.2.15 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Training embed_tokens in mixed precision to save VRAM\n",
      "Unsloth: Training lm_head in mixed precision to save VRAM\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 256, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "                      \"embed_tokens\", \"lm_head\"], #now also embeddings and lm_head\n",
    "    lora_alpha = 1,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = SEED,\n",
    "    use_rslora = True,  # We support rank stabilized LoRA\n",
    "    init_lora_weights = \"loftq\",\n",
    "    loftq_config = loftq_config, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# # this dataset has already fixed encoding using ftfy (as is used by me in the preprocessing steps of other datasets)\n",
    "# dataset_cs = load_dataset(\"HuggingFaceFW/fineweb-2\", \"ces_Latn\", split=\"train\")\n",
    "# #we need only texts\n",
    "# dataset_cs = dataset_cs.remove_columns([\"id\", \"dump\", \"url\", \"date\", \"file_path\", \"language\", \"language_score\", \"language_script\", \"minhash_cluster_size\", \"top_langs\"])\n",
    "# #shuffle to be sure we select \"random sample\"\n",
    "# dataset_cs = dataset_cs.shuffle(seed=42)\n",
    "# dataset_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_en = load_dataset(\"HuggingFaceFW/fineweb-edu\", \"sample-10BT\", split=\"train\")\n",
    "# dataset_en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_en = dataset_en.remove_columns([\"id\", \"dump\", \"url\", \"file_path\", \"language\", \"language_score\", \"token_count\", \"score\", \"int_score\"])\n",
    "# dataset_en.shuffle(seed=42)\n",
    "# dataset_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import concatenate_datasets\n",
    "# #select 40000 samples (for the initial exp.)\n",
    "\n",
    "# dataset_cs = dataset_cs.select(range(30000))\n",
    "# dataset_en = dataset_en.select(range(10000))\n",
    "\n",
    "# dataset = concatenate_datasets([dataset_cs, dataset_en])\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.save_to_disk(\"data/pretraining/init_31mix_cs-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 40000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "dataset = load_from_disk(\"data/pretraining/init_31mix_cs-en\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f09af05d2040669a1483de3a2e69a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    return {\"text\": [example + tokenizer.eos_token for example in examples[\"text\"]]}\n",
    "\n",
    "dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "V dnešní době je wifi připojení doma či v práci nezbytností. Ať už pracujete z domova, streamujete filmy nebo hrajete online hry, stabilní a rychlé připojení je klíčem k úspěchu. Frekvence wifi signálu je jedním z faktorů, který může ovlivnit rychlost a stabilitu připojení. V tomto článku se zaměříme na pět kroků, které vám pomohou optimálně nastavit frekvenci vašeho wifi signálu.\n",
      "Krok 1: Vyberte správný kanál\n",
      "Naše wifi sítě fungují na dvou frekvencích – 2,4 GHz a 5 GHz. Každá z těchto frekvencí má určité množství kanálů. Na frekvenci 2,4 GHz máme k dispozici 14 kanálů. Kanály jsou však překrývající se, což znamená, že pokud jsou dva sousedící kanály použity, mohou si vzájemně rušit. Proto se v praxi používají převážně kanály 1, 6 a 11.\n",
      "Na frekvenci 5 GHz je k dispozici více kanálů a ty jsou navíc nezávislé, tedy se nepřekrývají. To znamená, že na této frekvenci můžeme dosáhnout vyšší přenosové rychlosti.\n",
      "Krok 2: Změřte rušení\n",
      "Pokud chcete zjistit, který kanál je pro vás nejlepší, můžete použít různé aplikace k měření rušení wifi. Tyto aplikace skenují dostupné kanály a vyhodnotí, který z nich je nejméně rušený. Na základě těchto informací si pak můžete vybrat optimální kanál pro svou síť.\n",
      "Krok 3: Nastavte svůj router\n",
      "Po zjištění nejvhodnějšího kanálu se přihlaste do nastavení svého routeru. Většina routerů má možnost manuálního výběru kanálu. Přepněte tedy kanál na ten, který jste si vybrali jako optimální.\n",
      "Krok 4: Zkuste obě frekvence\n",
      "Pokud váš router podporuje obě frekvence, zkuste je obě. Frekvence 5 GHz nabízí vyšší přenosové rychlosti, ale má menší dosah a hůře prochází překážkami. Frekvence 2,4 GHz naopak nabízí menší rychlost, ale lepší dosah a schopnost procházet překážkami. Zkuste tedy obě frekvence a zjistěte, která z nich funguje pro vaši situaci lépe.\n",
      "Krok 5: Optimizujte umístění routeru\n",
      "Posledním krokem ke zlepšení frekvence wifi je optimální umístění routeru. Router by měl být umístěn co nejblíže zařízením, která se k wifi připojují. Měl by být také umístěn co nejdále od překážek, jako jsou stěny nebo elektronické zařízení, které mohou signál rušit.\n",
      "Závěr\n",
      "Optimalizace frekvence wifi může zlepšit rychlost a stabilitu vašeho připojení. Sledujte tedy naše pět kroků a zlepšete své online zážitky.\n",
      "Hledáte spolehlivý internetový tarif, který vám poskytne superrychlé a stabilní připojení, a to za férovou cenu? Pak je tu pro vás Tarif pevný Eri Internet! Získejte výhody jako roční platba, zřízení ZDARMA a sleva 600 Kč každý rok! A to není vše...\n",
      "Nečekejte, až vám unikne tato skvělá nabídka! Stačí jednoduše vyplnit formulář na našem webu a my se o vše postaráme. Navíc, pokud se přihlásíte nyní, získáte Eri LiveTV na dva měsíce zdarma a můžete sledovat všech 133 TV programů! Užijte si spolehlivý internet od Eri už dnes!<|end_of_text|>\n",
      "=========================\n",
      "stiskací mechanismus díky rýchloschnoucímu inkoustu a tvaru hrotu doporučeno i pro leváky zabezpečuje příjemné a pohodlné psaní tlačítko v barvě nápně ružové, zelené a svetlomodré pera dodávame s...\n",
      "Ke správné registraci chybí poslední krok.\n",
      "Zkontrolujte svůj e-mail (email@example.com) a kliknutím na odkaz\n",
      "ve zprávě potvrďte správnost registrace.\n",
      "Děkujeme, tým Artikul.<|end_of_text|>\n",
      "=========================\n",
      "Laserové řezání trubek\n",
      "- Řezání a opracování nerezových, ocelových uzavřených profilů na vysoce výkonném CNC laserovém systému s čistým řezem vhodným pod povrchovou úpravu\n",
      "- Použitím laseru je optimalizován výrobní proces. Při jediném výrobním kroku jsou vyřezány všechny otvory, komplexní kontury a upravena délka trubky. Tak jsou výrazně snižovány výrobní náklady ušetřením dalších operací a času (řezání, vrtání, frézování a vysekávání).\n",
      "- Dále jsou stále vyvíjeny nové a nové trubkové konstrukce, které vedou k redukci a zjednodušení následných výrobních operací. Potřeba i výroba svařovacích přípravků klesá vlivem používání rychlospojek a konektorů. Vodící kolíčky a zámky usnadňují následnou montáž.\n",
      "Laserový systém ADIGE LASERTUBE\n",
      "Flexibilní stroj italské společnosti BLM Group určený pro 3D opracování uzavřených (trubky a jekle) a otevřených ocelových profilů (L, C a U). Je vybavený výkyvnou řezací hlavou, která umožňuje řez pod úhlem tam, kde to následná technologie vyžaduje.\n",
      "- splňuje nejnáročnější požadavky na laserové řezání 3D profilů do Ø 220 mm\n",
      "- celkové rozřezání délkového profilu na opracované jednotlivé kusy výrazně zkracuje náklady a zjednodušuje postupy dalšího zpracování\n",
      "- vysoká přesnost řezaných otvorů (± 0,2 mm)\n",
      "- minimální ztráty z tyče\n",
      "- gravírování\n",
      "- technologické zámky různých tvarů\n",
      "- rohový výřez pro ohnutí profilu\n",
      "Zpracovatelné průřezy:\n",
      "- KRUHOVÝ s průměrem od 12 mm do 160 mm\n",
      "- ČTVERCOVÝ se stranou od 12 do 120\n",
      "- OBDELNÍKOVÝ a PLOCHOOVÁLNÝ s průřezem opsaným průměrem 170 mm. Síla stěny řezaného materiálu: max. 5 mm - řezáno dusíkem.<|end_of_text|>\n",
      "=========================\n",
      "Sportovní sluneční brýle Relax Victoria R5398FKód: 5015\n",
      "Detailní popis produktu\n",
      "Vlastnosti\n",
      "Velikost- Standard\n",
      "Barva- bílá\n",
      "Materiál- Grilamid TR90\n",
      "Pohlaví- pánské\n",
      "Pohlaví- dámské\n",
      "Materiál čočky- Nárazuvzdorný polykarbonát\n",
      "Barva čočky- hnědá\n",
      "Kategorie slunečního filtru- 2\n",
      "Povrchová úprava čočky- OCEAN SENSOR\n",
      "Certifikát\n",
      "Garantujeme prověřenou bezpečnost.\n",
      "TR90\n",
      "Extrémně lehký a přitom velmi odolný high-tec materiál s nadprůměrnou pružností a tvarovou pamětí, zvýšený komfort nošení.\n",
      "Protiskluzové plochy\n",
      "Protiskluzové nosníky a straničky. Zamezují skluzu brýlí, které perfektně drží na obličeji.\n",
      "Upravitelný nosník\n",
      "Větší pohodlí při nošení, nosník lze přizpůsobit tvaru nosu.\n",
      "Polykarbonát\n",
      "Téměř nerozbitný materiál čoček zajišťuje vyšší bezpečnost očí.\n",
      "Měkké pouzdro\n",
      "V měkkém mikrovláknovém pouzdru se brýle nepoškrábou a navíc jím lze brýle dobře vyčistit.\n",
      "Doplňkové parametry\n",
      "|Kategorie:||Brýle|\n",
      "|Záruka:||24|<|end_of_text|>\n",
      "=========================\n",
      "- 812 008\n",
      "Říká se tomu domýšlení. A je nebezpečné. Nebo snad pomáhá předcházet problémům? Dokonalá myšlenka v tomto komiksu vystihuje to, jak smýšlíme o ostatních v porovnání se skutečností. Co si o vás a situaci kolem vás říkají lidé skutečně versus co si myslíte, že si o ní domněle říkají? No, abychom se v tom neztratili, bude lepší si to zábavným způsobem ukázat v tomto dokonalém komiksu.\n",
      "- 304 131\n",
      "Ženská logika prostě není logická. Jak jinak byste vysvětlili, že pokud vás podvede holka, nakonec to všechno dopadne tak, že byste se měli omlouvat vy? No, nechtěli bychom teď být v kůži chudáka Derpa (nebo toho chlápka, co po dobu trvání komiksu drží ukázkový poker face). Ponaučení pro dnešní den je velmi jednoduché - když už máte potřebu svou přítelkyni sledovat, nikdy jí to nepřiznávejte.\n",
      "- 301 603\n",
      "Tento jednoduchý test osobnosti je založen na tom, že se člověk podívá na obrázku a řekne, která věc ho na něm zaujala jako první. V tomto případě existují 3 možnosti, které vám následně poodhalí skrytou tvář vaší osobnosti. Test si můžete vyzkoušet také s příteli, protože to, co hned vidí jeden člověk, může být druhému (minimálně v první moment) úplně skryto.\n",
      "- 307 788\n",
      "Každá hra má jiná specifika. Pojďme se podívat na jednotlivé střílečky, ve kterých máme přidělenou nějakou herní mechaniku. Jak si modelový hráč poradí s protivníky nebo jakou finty je možné použít? Někdy se bohužel i nejzkušenějším hráčům stává, že je jim k ničemu. Následující obrázky pochopí jen opravdový příznivce her. Rozklikněte si tedy hráčský komiks a připomeňte si časy, když jste prožívali to napětí.\n",
      "- 456 923\n",
      "V nynějším moderním světě je sport stejně tak populární, jako tomu bylo v dávných dobách. Každý druhý člověk chodí potit krev do posilovny, nebo cvičí jógu, běhá po ulicích v dopoledních hodinách nebo dodržuje přísný jídelníček plný zdravých pochutin. Je to tak, McDonaldu a ostatním fast foodům už odzvonilo a v módě jsou smoothie plné vitamínů pro skvělou rovnováhu a nastartování dne. Co se týče cvičení, jsou zde určitá fakta, řekněme mýty, kterým hodně lidí neustále věří a která jsou naprosto špatně! Jaké? Podívejte se sami!\n",
      "- 409 916\n",
      "Každá žena je jedinečná, to také v tom, co dělá. Podívejte se na komiks ženské příběhy z brightside.me, které vytvořila autorka Valeriya Fortuna a zaručeně se mohly každé z nich stát. Nejrůznější každodenní situace, občasné nezdary, chyby nebo zlomyslnosti žen. Přiznejme si, že každá má i své osobité manýry a některé pochopí jen málokterý muž, ale přes to bez něžného pohlaví by byl svět chmurnější a smutnější. Pouštíme tedy do světa další galerii o ženách a jejich životě z rubriky Srandovní obrázky.\n",
      "- 612 811\n",
      "Víte, proč dinosauři vyhinuli? A také to, jak vznikli? Dokonalý komiks od ItsTheTie vyobrazuje Boha, strejdu Satana a moment, který tam nahoře spečetil osud ještěrek před 65 miliony let (i když ony to nebyly ani tak ještěrky jako slepice, podle nejnovějších vědeckých důkazů, ale vem to čert, že?). Jsou to hadi a jdou do pekel! :-D\n",
      "- 304 950\n",
      "Velmi nás zajímá, kolik z vás vyhedá po přečtení této galerie odbornonu pomoc u psychologa, takže nám nezapomeňte sdělit svůj verdikt v komentáři! Máme pro vás další psychologický test, který odhalí vaše mentální poruchy, o kterých jste ani nevěděli! Stačí si udělat tento jednoduchý test. Pozorně se podívejte na každé z následujících šesti koleček. Nenechte se zmást, není to test u očního lékaře, ale probíhá téměř stejně. Vidíte v každém kolečku číslo? Pak je vše v pořádku. Pokud ale nějaké číslo nedokážete identifikovat, přečtěte si svoji charakteristiku!\n",
      "- 323 344\n",
      "Mazlení má rád každý. Někdo s opačným pohlavím, někdo se stejným pohlavím, jiný zase se svými domácími mazlíčky, či nedávnou zakoupeným kalashnikovem - to se týká více fanoušků armádních záležitostí. Proč je ale mazlení s partnerem tak důležité? A proč je vlastně nejlepší? V tomto poněkud krátkém, zato výstižném komiksu pochopíte.\n",
      "- 292 835\n",
      "Bezesporu k nejoblíbenějším se na internetu řadí komiksy s Hipsterkou a Hráčkou od Jago Dibuja. V této kolekci komiksů od tohoto autora si ukážeme několik dechberoucích momentů s dětmi a postavičkami z komiksu, které zcela očividně devalvují veškeré zásady a pravidla, jimiž se dospělí řídí vůči dětem. Zkrátka, hipsterka a hráčka si neberou servítky a s dětmi to opravdu \"umí\". :-D\n",
      "- 404 794\n",
      "Tohle je Harry Potter. A postavy, které nakreslil jeden *bezejmenný* umělec dle popisu v knize a současně je postavil vstříc kontrastu podoby, kterou tyto postavy získaly ve filmu. Jak moc se liší samotný Harry? A jak moc Hermiona? Slečna Grangerová byla původně pizizubkou, v originálním filmu však ztratila tento defekt a stala se poněkud atraktivní bordelmámou. Škoda, že se autoři neřídili popisem postav u dalších charakterů. A nebo se trefili? Co myslíte?\n",
      "- 374 057\n",
      "Poněkud cynické a plné sarkasmu jsou následující omalovánky, striktně určené jen dospělým lidem. To, kdybyste se fakt hodně nudili ve svém zaměstnání, můžete pak zkusit nalistovat na stránku s titulkem \"Pokuste se utéct z Friendzone\". V těchto omalovánkách totiž budete nejen omalovávat, nýbrž také utíkat. A nejen to. Podívejte se sami. A kreslete!\n",
      "- 393 788\n",
      "V této galerii se můžete přesvědčit, že většina postav z Harryho Pottera opravdu vyrostla do krásy. Příkladem může být třeba Matthew Lewis, který si zahrál postavu Neville Longbottoma. Odtud také nové přídavné jméno longbottoming, které bychom mohli přeložit jako dokrásyrostoucí.\n",
      "- 555 182\n",
      "Mezi námi ženami-občas máme složitý život, za který si občas můžeme i samy. A složitý životsi někdy žádá i složité řešení na složité situace. Není divu, že nám muži dost často nerozumí. Ano, hádáte správně, dnes pro vás máme vtipně udělanou galerii o ženách takových, jaké doopravdy jsou. Klidně se s vámi vsadím, že alespoň jednou v životě se každá žena ocitla v jedné z těch patnácti situací. Já třeba snad skoro ve všech. Zajímá vás logika žen? Pak tahle galerie čeká právě na vás!\n",
      "- 442 641\n",
      "Když jste byli malí, určitě vám rodiče říkali, abyste si nečetli po tmě, že si zkazíte oči. Možná, že některé z vás napadlo, že když potom sníte mrkev, která je podle vašich rodičů zdravá na oči, tak si ten zrak zlepšíte a oba dva jevy se vynulují. Teď vás ale musíme zklamat - nejenže to takhle na světě nefunguje, ale oba dva fakty jsou ve skutečnosti mýty. A patří do široké skupiny mýtů, které nám odmala vtloukali do hlavy. Takže o čem všem že nám to rodiče, příbuzní, ba dokonce i učitelé ve škole lhali?\n",
      "- 288 805\n",
      "Lehce starší generaci, ale ne zase úplně starou, dost možná udeří do očí fakt, že herec Samy Naceri, hlavní postava filmové série Taxi, má ve skutečnosti už 53 let. Bum. A to si ho celá řada z nás pamatuje jako mládence, co se prohání italskými ulicemi měst ve svým super ultra dokonalém fáru s cedulkou \"odvezu vás kamkoliv a za příplatek mi můžete v autě zvracet\". Které celebrity jsou však stejně staré a neřekli byste to do nich? V této galerii zahlédnete filmové here jako Silvester Stalone nebo dědečka Chucka Norrise. Vedle nich i Terryho Crewse a nebo kapitána Picarda z legendárního Star Treku.\n",
      "- 1 838 735\n",
      "A když říkáme \"až do konce\", tak myslíme zcela vážně, abyste tento rage komiks přečetli celý. Patří do zlaté sbírky nejlepších rage komiksů, které najdete na Trololol. A i pokud jste se s ním už někdy setkali, určitě vás repete neurazí. Protože tohle patří k nestárnoucím vtipům! :-D\n",
      "- 681 351\n",
      "Pokud máte velká prsa, nese to s sebou pochopitelně celou řadu výhod, zejména co se týče mužů. Nicméně každá bohatě obdařená žena vám potvrdí, že to má také velkou spoustu nevýhod, který vám dokážou pěkně znepříjemnit život.\n",
      "- 286 354\n",
      "Vztah dvou lidí je založen na více věcech, než je láska, tolerance a porozumění. Nemalou roli hraje i sexuální život. Asi všichni se shodneme na tom, že to, co se odehrává ve filmech pro dospělé, nemá vůbec nic společného s láskou. Dokážete si představit, že byste to dělali tak, jak se to dělá ve filmech pro dospělé? V této galerii vám ukážeme, jak by to vypadalo! Podívejte se sami.\n",
      "- 292 831\n",
      "O přestávce se ve škole dá dělat spousta věcí. Někdo ji využije k tomu, aby si dodělal úkol ze včerejška, jiný se zase snaží naučit se na test, další hraje hry na mobilu, kdežto někdo další si jde popovídat s kamarády. Ale o přestávkách se dají dělat i jiné věci, ačkoli by se dělat neměly. Nepřemýšleli jste někdy o tom, že byste si se svou polovičkou někam zalezli a trochu se tam uvolnili?\n",
      "- 417 710\n",
      "Autor mnoha komiksů a různých kreslených postav Yehuda Adi Devir ukázal světu svoji sérii obrázků, ve které je vykreslený život s jeho manželkou Mayou. Ilutrace jsou velmi vtipné, milé a zahřejí u srdce. Ať už jste ve vážném vztahu či manželství, najdete alespoň jeden obrázek, který se k vám hodí.\n",
      "- 441 042\n",
      "Autorka, která se vydává pod nickem C-Cassandra, zobrazila mužům 7 věcí, se kterými se ženy trápí a které muži nikdy neocení. Muži však zcela jistě ocení dvě věci, které ženy zase tak moc netrápí. První je nahota. A druhá je pivo v ruce. Takže pokud na to chcete jít jednoduše, prostě těchto jinak důležitých sedm bodů vynechte.<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "for row in dataset[:5][\"text\"]:\n",
    "    print(\"=========================\")\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnslothKLLossTrainer(UnslothTrainer):\n",
    "    def __init__(self, ref_model, kl_weight=0.1, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.ref_model = ref_model\n",
    "        self.ref_model.eval()\n",
    "        self.kl_weight = kl_weight\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        #account for the actual number of items in the batch\n",
    "        if num_items_in_batch is not None:\n",
    "            effective_batch_size = num_items_in_batch\n",
    "        else:\n",
    "            effective_batch_size = labels.size(0)\n",
    "        \n",
    "        #cross entropy loss\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "        loss_ce = loss_fct(logits.view(-1, logits.shape[-1]), labels.view(-1))\n",
    "        loss_ce = loss_ce / effective_batch_size # Scale by actual number of items\n",
    "\n",
    "        # KL loss\n",
    "        with torch.no_grad():\n",
    "            ref_outputs = self.ref_model(**inputs)\n",
    "            ref_logits = ref_outputs.logits\n",
    "        \n",
    "        loss_kl_fct = torch.nn.KLDivLoss(reduction=\"sum\")\n",
    "        loss_kl = loss_kl_fct(\n",
    "            torch.nn.functional.log_softmax(logits, dim=-1),\n",
    "            torch.nn.functional.softmax(ref_logits, dim=-1),\n",
    "        )\n",
    "        loss_kl = loss_kl / effective_batch_size # Scale by actual number of items\n",
    "\n",
    "        total_loss = loss_ce + self.kl_weight*loss_kl\n",
    "\n",
    "        return (total_loss, outputs) if return_outputs else total_loss\n",
    "\n",
    "from transformers.utils.import_utils import is_torch_xla_available\n",
    "#from transformers.trainer_utils import SaveStrategy\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "\n",
    "class PerplexityTrainer(UnslothTrainer):\n",
    "    # def training_step(self, model, inputs, num_items_in_batch):\n",
    "    #     loss = super().training_step(model, inputs, num_items_in_batch)\n",
    "\n",
    "    #     # log perplexity\n",
    "    #     perplexity = torch.exp(loss)\n",
    "    #     self.log({\"train_perplexity\": perplexity})\n",
    "\n",
    "    #     return loss\n",
    "    def _maybe_log_save_evaluate(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval):\n",
    "        if self.control.should_log and self.state.global_step > self._globalstep_last_logged:\n",
    "            if is_torch_xla_available():\n",
    "                xm.mark_step()\n",
    "\n",
    "            logs: Dict[str, float] = {}\n",
    "\n",
    "            # all_gather + mean() to get average loss over all processes\n",
    "            tr_loss_scalar = self._nested_gather(tr_loss).mean().item()\n",
    "\n",
    "            # reset tr_loss to zero\n",
    "            tr_loss -= tr_loss\n",
    "\n",
    "            loss = round(tr_loss_scalar / (self.state.global_step - self._globalstep_last_logged), 4)\n",
    "            logs[\"loss\"] = loss\n",
    "\n",
    "            #PERPLEXITY\n",
    "            logs[\"perplexity\"] = round(float(np.exp(tr_loss_scalar)), 4)\n",
    "            #########################\n",
    "\n",
    "\n",
    "            if grad_norm is not None:\n",
    "                logs[\"grad_norm\"] = grad_norm.detach().item() if isinstance(grad_norm, torch.Tensor) else grad_norm\n",
    "            logs[\"learning_rate\"] = self._get_learning_rate()\n",
    "\n",
    "            self._total_loss_scalar += tr_loss_scalar\n",
    "            self._globalstep_last_logged = self.state.global_step\n",
    "            self.store_flos()\n",
    "\n",
    "            self.log(logs)\n",
    "\n",
    "        metrics = None\n",
    "        if self.control.should_evaluate:\n",
    "            metrics = self._evaluate(trial, ignore_keys_for_eval)\n",
    "\n",
    "        if self.control.should_save:\n",
    "            self._save_checkpoint(model, metrics=metrics)\n",
    "            self.control = self.callback_handler.on_save(self.args, self.state, self.control)\n",
    "\n",
    "TrainerClass = PerplexityTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EvalPrediction\n",
    "import numpy as np\n",
    "\n",
    "#prepare perplexity computation\n",
    "def compute_metrics(pred: EvalPrediction):\n",
    "    losses = pred.losses\n",
    "\n",
    "    mean_loss = np.mean(losses)\n",
    "\n",
    "    try:\n",
    "        perplexity = np.exp(mean_loss)\n",
    "    except OverflowError:\n",
    "        perplexity = float(\"inf\")\n",
    "\n",
    "    return {\"perplexity\": perplexity}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlynatom/master-thesis-repository-tomas-mlynar/unsloth_compiled_cache/UnslothSFTTrainer.py:578: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/mlynatom/master-thesis-repository-tomas-mlynar/unsloth_compiled_cache/UnslothSFTTrainer.py:592: UserWarning: You passed a `dataset_num_proc` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/mlynatom/master-thesis-repository-tomas-mlynar/unsloth_compiled_cache/UnslothSFTTrainer.py:606: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898ffbd7b42b435d9c429d38fb3dc77d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/40000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "trainer = UnslothTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset.shuffle(seed=SEED),\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    # ref_model=copy.deepcopy(model),\n",
    "    #compute_metrics=compute_metrics,\n",
    "    \n",
    "    args = UnslothTrainingArguments(\n",
    "        per_device_train_batch_size = 64,\n",
    "        gradient_accumulation_steps = 16,\n",
    "        warmup_ratio = 0.05,\n",
    "        num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        #max_steps = 1000,\n",
    "        learning_rate = 2e-4,\n",
    "        embedding_learning_rate = 4e-5,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = SEED,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"wandb\", # Use this for WandB etc\n",
    "        run_name=\"llama3.2-1b-cp-exp-loftq\",\n",
    "        # eval_strategy = \"steps\",\n",
    "        # eval_steps = 50,\n",
    "        \n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA A100-SXM4-40GB. Max memory = 39.381 GB.\n",
      "3.514 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "#Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 40,000 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 64 | Gradient Accumulation steps = 16\n",
      "\\        /    Total batch size = 1,024 | Total steps = 39\n",
      " \"-____-\"     Number of trainable parameters = 705,691,648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Setting lr = 4.00e-05 instead of 2.00e-04 for embed_tokens.\n",
      "Unsloth: Setting lr = 4.00e-05 instead of 2.00e-04 for lm_head.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmlynatom\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mlynatom/master-thesis-repository-tomas-mlynar/wandb/run-20250226_093358-ioydrdok</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mlynatom/huggingface/runs/ioydrdok' target=\"_blank\">llama3.2-1b-cp-exp-loftq</a></strong> to <a href='https://wandb.ai/mlynatom/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mlynatom/huggingface' target=\"_blank\">https://wandb.ai/mlynatom/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mlynatom/huggingface/runs/ioydrdok' target=\"_blank\">https://wandb.ai/mlynatom/huggingface/runs/ioydrdok</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6/39 14:53 < 2:02:54, 0.00 it/s, Epoch 0.13/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.909600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.845400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.885000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlynatom/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/unsloth/models/_utils.py:592: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  source = re.sub(\"([^\\.])nn\\.\", r\"\\1torch.nn.\", source)\n",
      "/home/mlynatom/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/unsloth/models/_utils.py:855: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  \"self.rotary_emb = .+?\\)\", function,\n",
      "/home/mlynatom/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/unsloth/models/_utils.py:955: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  \"self.rotary_emb = .+?\\)\", function,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:380\u001b[0m, in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
      "File \u001b[0;32m<string>:31\u001b[0m, in \u001b[0;36m_unsloth_training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/unsloth/models/_utils.py:1077\u001b[0m, in \u001b[0;36m_unsloth_pre_compute_loss\u001b[0;34m(self, model, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1071\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[1;32m   1072\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsloth: Not an error, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept `num_items_in_batch`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing gradient accumulation will be very slightly less accurate.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m   1074\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1075\u001b[0m     )\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m-> 1077\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_compute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/transformers/trainer.py:3633\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3631\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3632\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3633\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3634\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3635\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/accelerate/utils/operations.py:820\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/accelerate/utils/operations.py:808\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/torch/_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m prior \u001b[38;5;241m=\u001b[39m _maybe_set_eval_frame(callback)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    634\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/unsloth/models/llama.py:1216\u001b[0m, in \u001b[0;36mPeftModelForCausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, num_logits_to_keep, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_dynamo\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mPeftModelForCausalLM_fast_forward\u001b[39m(\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1215\u001b[0m ):\n\u001b[0;32m-> 1216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:197\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/unsloth/models/llama.py:1109\u001b[0m, in \u001b[0;36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m RETURN_LOGITS \u001b[38;5;129;01mand\u001b[39;00m HAS_CUT_CROSS_ENTROPY \u001b[38;5;129;01mand\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1108\u001b[0m     n_items \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_items\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1109\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mfused_linear_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlm_weight\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlm_head\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogit_softcapping\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogit_softcapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1117\u001b[0m         output \u001b[38;5;241m=\u001b[39m (logits,) \u001b[38;5;241m+\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/unsloth_zoo/loss_utils.py:154\u001b[0m, in \u001b[0;36mfused_linear_cross_entropy\u001b[0;34m(hidden_states, lm_weight, labels, num_items_in_batch, ignore_index, reduction, logit_softcapping, accuracy_threshold)\u001b[0m\n\u001b[1;32m    152\u001b[0m reduction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logit_softcapping \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: logit_softcapping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlm_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43msoftcap\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogit_softcapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshift\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_eps\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maccuracy_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m num_items_in_batch\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/cut_cross_entropy/linear_cross_entropy.py:58\u001b[0m, in \u001b[0;36mlinear_cross_entropy\u001b[0;34m(e, c, targets, ignore_index, softcap, reduction, shift, filter_eps, impl)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     54\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCCE does not support MacOS. Please use torch_compile when running on MacOS instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m         )\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m cce_linear_cross_entropy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcce_linear_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoftcap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_eps\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_compile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_compile_linear_cross_entropy(\n\u001b[1;32m     63\u001b[0m         e, c, targets, ignore_index, softcap, reduction, shift\n\u001b[1;32m     64\u001b[0m     )\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/cut_cross_entropy/cce.py:163\u001b[0m, in \u001b[0;36mcce_linear_cross_entropy\u001b[0;34m(e, c, targets, ignore_index, softcap, reduction, shift, filter_eps)\u001b[0m\n\u001b[1;32m    160\u001b[0m e \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    161\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m--> 163\u001b[0m valids \u001b[38;5;241m=\u001b[39m \u001b[43m_build_flat_valids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m e \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    166\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[0;32m~/master-thesis-repository-tomas-mlynar/venv/master_venv/lib/python3.12/site-packages/cut_cross_entropy/utils.py:38\u001b[0m, in \u001b[0;36m_build_flat_valids\u001b[0;34m(targets, ignore_index, shift)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m---> 38\u001b[0m valids \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m shift:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m valids\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4329.0353 seconds used for training.\n",
      "72.15 minutes used for training.\n",
      "Peak reserved memory = 19.932 GB.\n",
      "Peak reserved memory for training = 17.297 GB.\n",
      "Peak reserved memory % of max memory = 50.613 %.\n",
      "Peak reserved memory for training % of max memory = 43.922 %.\n"
     ]
    }
   ],
   "source": [
    "#Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
